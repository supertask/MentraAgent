"""
Modal GPU Server Application
WhisperXã€pyannoteã€Vision LLMã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªAIå‡¦ç†
"""

import modal
import os
from typing import Dict, List, Any, Optional
from datetime import datetime

# Modalã‚¢ãƒ—ãƒªã®ä½œæˆ
app = modal.App("realworld-agent")

# GPUç’°å¢ƒã¨ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ã®Volume
models_volume = modal.Volume.from_name("realworld-agent-models", create_if_missing=True)

# Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ã®å®šç¾©
image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install(
        "ffmpeg",
        "git",
        "pkg-config",
        "libavformat-dev",
        "libavcodec-dev",
        "libavdevice-dev",
        "libavutil-dev",
        "libswscale-dev",
        "libswresample-dev",
        "libavfilter-dev",
    )
    .pip_install(
        # ä»•æ§˜æ›¸ç”Ÿæˆã«å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆæœ€å°æ§‹æˆï¼‰
        "anthropic>=0.40.0",
        "openai>=1.54.0",
        "Pillow>=10.2.0",
        "python-dotenv>=1.0.1",
        "fastapi[all]>=0.109.2",
        "pydantic>=2.6.1",
        # éŸ³å£°æ–‡å­—èµ·ã“ã—ç”¨ï¼ˆç¾åœ¨ã¯ç„¡åŠ¹åŒ–ï¼‰
        # "torch==2.1.0",
        # "torchaudio==2.1.0",
        # "whisperx==3.1.1",
        # "pyannote.audio==3.1.1",
        # "openai-whisper==20231117",
        # "faster-whisper==0.9.0",
        # "numpy==1.24.3",
        # "scipy==1.11.4",
        # "scikit-learn==1.3.2",
        # "opencv-python-headless==4.8.1.78",
    )
)

# Secretsï¼ˆç’°å¢ƒå¤‰æ•°ï¼‰
secrets = [
    modal.Secret.from_name("realworld-agent-secrets"),
]


@app.cls(
    image=image,
    # gpu="A10G",  # GPUã¯éŸ³å£°æ–‡å­—èµ·ã“ã—æ™‚ã®ã¿å¿…è¦ï¼ˆç¾åœ¨ã¯ç„¡åŠ¹åŒ–ï¼‰
    secrets=secrets,
    volumes={"/models": models_volume},
    timeout=600,  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    # keep_warm=1,  # ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚ç„¡åŠ¹åŒ–ï¼ˆã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆã‚ã‚Šï¼š20-60ç§’ï¼‰
)
class RealworldAgentGPU:
    """
    GPUã‚’ä½¿ç”¨ã—ãŸAIå‡¦ç†ã‚¯ãƒ©ã‚¹
    """

    def __init__(self):
        """åˆæœŸåŒ–"""
        self.whisperx_model = None
        self.diarization_pipeline = None
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.anthropic_api_key = os.getenv("ANTHROPIC_API_KEY")
        self.primary_llm_provider = os.getenv("PRIMARY_LLM_PROVIDER", "openai")
        self.enable_llm_fallback = os.getenv("ENABLE_LLM_FALLBACK", "true").lower() == "true"
        self.openai_model = os.getenv("OPENAI_MODEL", "gpt-4o")
        self.anthropic_model = os.getenv("ANTHROPIC_MODEL", "claude-3-5-sonnet-20241022")

    @modal.enter()
    def load_models(self):
        """ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆèµ·å‹•æ™‚ã«1å›ã ã‘å®Ÿè¡Œï¼‰"""
        print("ğŸš€ åˆæœŸåŒ–ä¸­...")
        print("âœ… åˆæœŸåŒ–å®Œäº†")
        print("â„¹ï¸  WhisperX/pyannoteã¯ç¾åœ¨ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼ˆä»•æ§˜æ›¸ç”Ÿæˆã®ã¿åˆ©ç”¨å¯èƒ½ï¼‰")

    @modal.method()
    def transcribe_audio(
        self,
        audio_path: str,
        language: str = "ja",
        enable_diarization: bool = True,
        min_speakers: int = 1,
        max_speakers: int = 10,
    ) -> Dict[str, Any]:
        """
        éŸ³å£°æ–‡å­—èµ·ã“ã—ï¼ˆWhisperX + è©±è€…åˆ†é›¢ï¼‰

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            language: è¨€èªã‚³ãƒ¼ãƒ‰
            enable_diarization: è©±è€…åˆ†é›¢ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹
            min_speakers: æœ€å°è©±è€…æ•°
            max_speakers: æœ€å¤§è©±è€…æ•°

        Returns:
            æ–‡å­—èµ·ã“ã—çµæœ
        """
        import whisperx

        print(f"ğŸ™ï¸ éŸ³å£°æ–‡å­—èµ·ã“ã—é–‹å§‹: {audio_path}")

        try:
            # éŸ³å£°èª­ã¿è¾¼ã¿
            audio = whisperx.load_audio(audio_path)

            # WhisperXã§æ–‡å­—èµ·ã“ã—
            print("ğŸ“ WhisperXã§æ–‡å­—èµ·ã“ã—ä¸­...")
            result = self.whisperx_model.transcribe(
                audio,
                language=language,
                batch_size=16,
            )

            # å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ
            print("ğŸ”¤ å˜èªãƒ¬ãƒ™ãƒ«ã®ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆä¸­...")
            model_a, metadata = whisperx.load_align_model(
                language_code=language,
                device=self.device,
            )
            result = whisperx.align(
                result["segments"],
                model_a,
                metadata,
                audio,
                self.device,
                return_char_alignments=False,
            )

            # è©±è€…åˆ†é›¢
            speakers_result = None
            if enable_diarization and self.diarization_pipeline:
                print("ğŸ¤ è©±è€…åˆ†é›¢ä¸­...")
                try:
                    diarization = self.diarization_pipeline(
                        audio_path,
                        min_speakers=min_speakers,
                        max_speakers=max_speakers,
                    )

                    # è©±è€…æƒ…å ±ã‚’çµæœã«çµ±åˆ
                    result = whisperx.assign_word_speakers(diarization, result)
                    speakers_result = self._extract_speakers(result)
                    print(f"âœ… {len(set(speakers_result))} äººã®è©±è€…ã‚’æ¤œå‡º")
                except Exception as e:
                    print(f"âš ï¸ è©±è€…åˆ†é›¢ã‚¨ãƒ©ãƒ¼: {e}")

            # çµæœã®æ•´å½¢
            output = {
                "text": " ".join([seg["text"] for seg in result["segments"]]),
                "segments": result["segments"],
                "language": language,
                "speakers": speakers_result,
                "timestamp": datetime.now().isoformat(),
            }

            print("âœ… éŸ³å£°æ–‡å­—èµ·ã“ã—å®Œäº†")
            return output

        except Exception as e:
            print(f"âŒ éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    @modal.method()
    def analyze_image(
        self,
        image_data: bytes,
        prompt: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        ç”»åƒåˆ†æï¼ˆClaude Vision or GPT-4Vï¼‰

        Args:
            image_data: ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¤ãƒˆåˆ—ï¼‰
            prompt: ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

        Returns:
            ç”»åƒåˆ†æçµæœ
        """
        import base64

        print(f"ğŸ–¼ï¸ ç”»åƒåˆ†æé–‹å§‹ï¼ˆãƒ—ãƒ©ã‚¤ãƒãƒª: {self.primary_llm_provider}ï¼‰")

        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        image_base64 = base64.b64encode(image_data).decode("utf-8")

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        if not prompt:
            prompt = """
ã“ã®ç”»åƒã‚’è©³ã—ãåˆ†æã—ã¦ãã ã•ã„ï¼š
1. ä½•ãŒæ˜ ã£ã¦ã„ã‚‹ã‹ï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€äººç‰©ã€é¢¨æ™¯ãªã©ï¼‰
2. æŠ€è¡“çš„ãªè¦ç´ ï¼ˆã‚³ãƒ¼ãƒ‰ã€å›³ã€UIã€ãƒ›ãƒ¯ã‚¤ãƒˆãƒœãƒ¼ãƒ‰ãªã©ï¼‰
3. é‡è¦ãªæƒ…å ±ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã€æ•°å­—ã€è¨˜å·ãªã©ï¼‰
4. å…¨ä½“çš„ãªã‚·ãƒ¼ãƒ³ã®èª¬æ˜

JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{
  "description": "å…¨ä½“çš„ãªèª¬æ˜",
  "objects": ["æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãƒªã‚¹ãƒˆ"],
  "text": "ç”»åƒå†…ã®ãƒ†ã‚­ã‚¹ãƒˆ",
  "scene": "ã‚·ãƒ¼ãƒ³ã®ç¨®é¡",
  "technical_elements": ["æŠ€è¡“çš„ãªè¦ç´ "]
}
"""

        try:
            # ãƒ—ãƒ©ã‚¤ãƒãƒªLLMã§è©¦è¡Œ
            result = self._analyze_image_with_provider(
                image_base64, 
                prompt, 
                self.primary_llm_provider
            )
            return result

        except Exception as e:
            print(f"âš ï¸ ãƒ—ãƒ©ã‚¤ãƒãƒªLLMï¼ˆ{self.primary_llm_provider}ï¼‰ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒæœ‰åŠ¹ãªå ´åˆ
            if self.enable_llm_fallback:
                fallback_provider = "anthropic" if self.primary_llm_provider == "openai" else "openai"
                print(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {fallback_provider}ã§å†è©¦è¡Œ")
                
                try:
                    result = self._analyze_image_with_provider(
                        image_base64, 
                        prompt, 
                        fallback_provider
                    )
                    return result
                except Exception as fallback_error:
                    print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯LLMã‚‚ã‚¨ãƒ©ãƒ¼: {fallback_error}")
                    raise
            else:
                raise

    @modal.method()
    def detect_scene_changes(
        self,
        frames: List[bytes],
        threshold: float = 0.3,
    ) -> List[int]:
        """
        ã‚·ãƒ¼ãƒ³å¤‰åŒ–æ¤œå‡º

        Args:
            frames: ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã®ãƒªã‚¹ãƒˆ
            threshold: å¤‰åŒ–æ¤œå‡ºã®é–¾å€¤

        Returns:
            ã‚·ãƒ¼ãƒ³å¤‰åŒ–ãŒæ¤œå‡ºã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        """
        import cv2
        import numpy as np

        print(f"ğŸ¬ ã‚·ãƒ¼ãƒ³å¤‰åŒ–æ¤œå‡ºé–‹å§‹ï¼ˆ{len(frames)} ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰")

        try:
            changes = []
            prev_frame = None

            for i, frame_data in enumerate(frames):
                # ãƒã‚¤ãƒˆåˆ—ã‹ã‚‰ç”»åƒã«å¤‰æ›
                nparr = np.frombuffer(frame_data, np.uint8)
                frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

                if prev_frame is not None:
                    # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ æ¯”è¼ƒ
                    hist1 = cv2.calcHist([prev_frame], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])
                    hist2 = cv2.calcHist([frame], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])

                    cv2.normalize(hist1, hist1)
                    cv2.normalize(hist2, hist2)

                    # é¡ä¼¼åº¦è¨ˆç®—
                    similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)

                    # é–¾å€¤ä»¥ä¸‹ãªã‚‰å¤‰åŒ–ã¨ã¿ãªã™
                    if similarity < (1.0 - threshold):
                        changes.append(i)
                        print(f"  ğŸ“ ãƒ•ãƒ¬ãƒ¼ãƒ  {i}: å¤‰åŒ–æ¤œå‡ºï¼ˆé¡ä¼¼åº¦: {similarity:.3f}ï¼‰")

                prev_frame = frame

            print(f"âœ… {len(changes)} ç®‡æ‰€ã®ã‚·ãƒ¼ãƒ³å¤‰åŒ–ã‚’æ¤œå‡º")
            return changes

        except Exception as e:
            print(f"âŒ ã‚·ãƒ¼ãƒ³å¤‰åŒ–æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            raise

    @modal.method()
    def generate_specification(
        self,
        context: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        ä»•æ§˜æ›¸ç”Ÿæˆ

        Args:
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ï¼ˆæ–‡å­—èµ·ã“ã—ã€ç”»åƒãªã©ï¼‰

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸä»•æ§˜æ›¸
        """
        print(f"ğŸ“„ ä»•æ§˜æ›¸ç”Ÿæˆé–‹å§‹ï¼ˆãƒ—ãƒ©ã‚¤ãƒãƒª: {self.primary_llm_provider}ï¼‰")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
        prompt = self._build_specification_prompt(context)

        try:
            # ãƒ—ãƒ©ã‚¤ãƒãƒªLLMã§è©¦è¡Œ
            result = self._generate_text_with_provider(
                prompt,
                self.primary_llm_provider,
                max_tokens=4096
            )
            
            specification_text = result["content"]
            
            output = {
                "title": self._extract_title(specification_text),
                "content": specification_text,
                "model": result["model"],
                "timestamp": datetime.now().isoformat(),
            }

            print("âœ… ä»•æ§˜æ›¸ç”Ÿæˆå®Œäº†")
            return output

        except Exception as e:
            print(f"âš ï¸ ãƒ—ãƒ©ã‚¤ãƒãƒªLLMï¼ˆ{self.primary_llm_provider}ï¼‰ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒæœ‰åŠ¹ãªå ´åˆ
            if self.enable_llm_fallback:
                fallback_provider = "anthropic" if self.primary_llm_provider == "openai" else "openai"
                print(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {fallback_provider}ã§å†è©¦è¡Œ")
                
                try:
                    result = self._generate_text_with_provider(
                        prompt,
                        fallback_provider,
                        max_tokens=4096
                    )
                    
                    specification_text = result["content"]
                    
                    output = {
                        "title": self._extract_title(specification_text),
                        "content": specification_text,
                        "model": result["model"],
                        "timestamp": datetime.now().isoformat(),
                    }

                    print("âœ… ä»•æ§˜æ›¸ç”Ÿæˆå®Œäº†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰")
                    return output
                    
                except Exception as fallback_error:
                    print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯LLMã‚‚ã‚¨ãƒ©ãƒ¼: {fallback_error}")
                    raise
            else:
                raise

    @modal.method()
    def generate_code(
        self,
        request: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ

        Args:
            request: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                - prompt: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ï¼ˆå¿…é ˆï¼‰
                - context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ï¼ˆæ–‡å­—èµ·ã“ã—ã€ä»•æ§˜æ›¸ãªã©ï¼‰
                - language: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                - framework: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

        Returns:
            ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰
        """
        print(f"ğŸ’» ã‚³ãƒ¼ãƒ‰ç”Ÿæˆé–‹å§‹ï¼ˆãƒ—ãƒ©ã‚¤ãƒãƒª: {self.primary_llm_provider}ï¼‰")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
        prompt = self._build_code_generation_prompt(request)

        try:
            # ãƒ—ãƒ©ã‚¤ãƒãƒªLLMã§è©¦è¡Œ
            result = self._generate_text_with_provider(
                prompt,
                self.primary_llm_provider,
                max_tokens=8192  # ã‚³ãƒ¼ãƒ‰ç”Ÿæˆã¯é•·ã‚ã«
            )
            
            code_text = result["content"]
            
            # ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®æŠ½å‡º
            files = self._extract_code_files(code_text)
            
            # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã®æŠ½å‡º
            project_summary = self._extract_project_summary(code_text)
            
            output = {
                "files": files,
                "dependencies": self._extract_dependencies(code_text),
                "instructions": self._extract_instructions(code_text),
                "summary": project_summary,
                "model": result["model"],
                "timestamp": datetime.now().isoformat(),
            }

            print(f"âœ… ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†ï¼ˆ{len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
            print(f"ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: {project_summary['name']}")
            return output

        except Exception as e:
            print(f"âš ï¸ ãƒ—ãƒ©ã‚¤ãƒãƒªLLMï¼ˆ{self.primary_llm_provider}ï¼‰ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒæœ‰åŠ¹ãªå ´åˆ
            if self.enable_llm_fallback:
                fallback_provider = "anthropic" if self.primary_llm_provider == "openai" else "openai"
                print(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: {fallback_provider}ã§å†è©¦è¡Œ")
                
                try:
                    result = self._generate_text_with_provider(
                        prompt,
                        fallback_provider,
                        max_tokens=8192
                    )
                    
                    code_text = result["content"]
                    files = self._extract_code_files(code_text)
                    project_summary = self._extract_project_summary(code_text)
                    
                    output = {
                        "files": files,
                        "dependencies": self._extract_dependencies(code_text),
                        "instructions": self._extract_instructions(code_text),
                        "summary": project_summary,
                        "model": result["model"],
                        "timestamp": datetime.now().isoformat(),
                    }

                    print(f"âœ… ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€{len(files)}ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰")
                    print(f"ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: {project_summary['name']}")
                    return output
                    
                except Exception as fallback_error:
                    print(f"âŒ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯LLMã‚‚ã‚¨ãƒ©ãƒ¼: {fallback_error}")
                    raise
            else:
                raise

    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰

    def _extract_speakers(self, result: Dict) -> List[str]:
        """è©±è€…ãƒªã‚¹ãƒˆã‚’æŠ½å‡º"""
        speakers = set()
        for segment in result.get("segments", []):
            if "speaker" in segment:
                speakers.add(segment["speaker"])
        return sorted(list(speakers))

    def _build_specification_prompt(self, context: Dict[str, Any]) -> str:
        """ä»•æ§˜æ›¸ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        transcriptions = context.get("transcriptions", [])
        photos = context.get("photos", [])

        prompt = """
ä»¥ä¸‹ã®ä¼šè­°ãƒ»ä½œæ¥­ã®è¨˜éŒ²ã‹ã‚‰ã€æŠ€è¡“ä»•æ§˜æ›¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

# æ–‡å­—èµ·ã“ã—
"""
        for trans in transcriptions[-20:]:  # æœ€æ–°20ä»¶
            speaker = trans.get("speaker", "ä¸æ˜")
            text = trans.get("text", "")
            prompt += f"\n[{speaker}] {text}"

        prompt += """

# è¦æ±‚äº‹é …
- æ˜ç¢ºã§æ§‹é€ åŒ–ã•ã‚ŒãŸä»•æ§˜æ›¸ã‚’ä½œæˆ
- è¦ä»¶ã€æŠ€è¡“è©³ç´°ã€å®Ÿè£…æ‰‹é †ã‚’å«ã‚ã‚‹
- Markdownå½¢å¼ã§å‡ºåŠ›

# å‡ºåŠ›å½¢å¼
## ã‚¿ã‚¤ãƒˆãƒ«
## æ¦‚è¦
## è¦ä»¶
### æ©Ÿèƒ½è¦ä»¶
### éæ©Ÿèƒ½è¦ä»¶
## æŠ€è¡“è©³ç´°
## å®Ÿè£…æ‰‹é †
## å‚™è€ƒ
"""
        return prompt

    def _extract_title(self, text: str) -> str:
        """ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º"""
        lines = text.split("\n")
        for line in lines:
            if line.startswith("# "):
                return line.replace("# ", "").strip()
        return "ä»•æ§˜æ›¸"

    def _build_code_generation_prompt(self, request: Dict[str, Any]) -> str:
        """ã‚³ãƒ¼ãƒ‰ç”Ÿæˆç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        user_prompt = request.get("prompt", "")
        context = request.get("context", {})
        language = request.get("language", "")
        framework = request.get("framework", "")
        
        transcriptions = context.get("transcriptions", [])
        specification = context.get("specification", "")
        
        prompt = f"""
ã‚ãªãŸã¯ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
ä»¥ä¸‹ã®è¦æ±‚ã«åŸºã¥ã„ã¦ã€å®Ÿè£…å¯èƒ½ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚
{user_prompt}

"""
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ 
        if specification:
            prompt += f"""
# ä»•æ§˜æ›¸
{specification}

"""
        
        if transcriptions:
            prompt += """
# ä¼šè­°ã®æ–‡å­—èµ·ã“ã—
"""
            for trans in transcriptions[-10:]:  # æœ€æ–°10ä»¶
                speaker = trans.get("speaker", "ä¸æ˜")
                text = trans.get("text", "")
                prompt += f"\n[{speaker}] {text}"
            prompt += "\n"
        
        # è¨€èªãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯æŒ‡å®š
        if language:
            prompt += f"""
# ä½¿ç”¨ã™ã‚‹è¨€èª
{language}
"""
        
        if framework:
            prompt += f"""
# ä½¿ç”¨ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
{framework}
"""
        
        prompt += """

---

# å‡ºåŠ›å½¢å¼

ä»¥ä¸‹ã®å½¢å¼ã§**å¿…ãšå³å¯†ã«**å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯**å¿…é ˆ**ã§ã™ã€‚

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: ã€è¦æ±‚å†…å®¹ã«åŸºã¥ã„ãŸå…·ä½“çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã€‘
èª¬æ˜: ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„ã¨æ©Ÿèƒ½ã‚’1-2è¡Œã§ç°¡æ½”ã«èª¬æ˜ã€‘
ä¸»ãªæ©Ÿèƒ½:
- ã€æ©Ÿèƒ½1: å…·ä½“çš„ãªèª¬æ˜ã€‘
- ã€æ©Ÿèƒ½2: å…·ä½“çš„ãªèª¬æ˜ã€‘
- ã€æ©Ÿèƒ½3: å…·ä½“çš„ãªèª¬æ˜ã€‘

**ä¾‹ï¼ˆæ§‹é€ è¨ˆç®—ã®å ´åˆï¼‰:**
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå: å»ºç¯‰æ§‹é€ è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ 
èª¬æ˜: è¨­è¨ˆå›³ã¨ææ–™ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å»ºç¯‰ç‰©ã®æ§‹é€ å®‰å…¨æ€§ã‚’è‡ªå‹•è¨ˆç®—ãƒ»æ¤œè¨¼ã™ã‚‹Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
ä¸»ãªæ©Ÿèƒ½:
- è¨­è¨ˆå›³ç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨è§£æ
- ææ–™ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå…¥åŠ›
- æ§‹é€ è¨ˆç®—ã®è‡ªå‹•å®Ÿè¡Œã¨çµæœè¡¨ç¤º

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
- è¨€èª: ã€ä½¿ç”¨è¨€èªã€‘
- ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯: ã€ä½¿ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ï¼ˆã‚ã‚‹å ´åˆï¼‰ã€‘
- ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª: ã€ä¸»è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§ã€‘

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 
```mermaid
graph TD
    A[ã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆåã€‘] --> B[ã€ä¸»è¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã€‘]
    B --> C[ã€ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«1åã€‘]
    B --> D[ã€ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«2åã€‘]
    C --> E[ã€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£åã€‘]
    D --> E
    
    style A fill:#667eea
    style B fill:#764ba2
    style C fill:#f093fb
    style D fill:#f093fb
    style E fill:#4facfe
```

**é‡è¦: å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã«åˆã‚ã›ã¦Mermaidå›³ã‚’ä½œæˆã—ã¦ãã ã•ã„**

## ä¾å­˜é–¢ä¿‚
```
ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸1==ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‘
ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸2==ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‘
ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸3==ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‘
```

---

## ã‚³ãƒ¼ãƒ‰

### ãƒ•ã‚¡ã‚¤ãƒ«: README.md
```markdown
# ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼ˆè¦æ±‚å†…å®¹ã«åŸºã¥ã„ãŸå…·ä½“çš„ãªåå‰ï¼‰ã€‘

> ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç°¡æ½”ãªèª¬æ˜ï¼ˆ1è¡Œï¼‰ã€‘

## ğŸ“‹ æ¦‚è¦

ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®çš„ã€èƒŒæ™¯ã€è§£æ±ºã™ã‚‹èª²é¡Œã‚’3-5è¡Œã§èª¬æ˜ã€‘

## âœ¨ ä¸»ãªæ©Ÿèƒ½

- **ã€æ©Ÿèƒ½1ã€‘**: ã€è©³ç´°èª¬æ˜ã€‘
- **ã€æ©Ÿèƒ½2ã€‘**: ã€è©³ç´°èª¬æ˜ã€‘  
- **ã€æ©Ÿèƒ½3ã€‘**: ã€è©³ç´°èª¬æ˜ã€‘

## ğŸ—ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

\```mermaid
graph TD
    A[ã€ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€‘] --> B[ã€ãƒ¡ã‚¤ãƒ³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã€‘]
    B --> C[ã€ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«1ã€‘]
    B --> D[ã€ã‚µãƒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«2ã€‘]
    C --> E[ã€ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã€‘]
    D --> E
    
    style A fill:#667eea
    style B fill:#764ba2
    style C fill:#f093fb
    style D fill:#f093fb
    style E fill:#4facfe
\```

## ğŸ› ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **è¨€èª**: ã€è¨€èªã€‘
- **ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯**: ã€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã€‘
- **ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª**: ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒª1ã€‘ã€ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒª2ã€‘ã€ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒª3ã€‘

## ğŸ“¦ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### å¿…è¦ãªç’°å¢ƒ

- ã€è¨€èªåã€‘ ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€‘ä»¥ä¸Š
- ã€ãã®ä»–ã®ä¾å­˜é–¢ä¿‚ã€‘

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †

\```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone <repository-url>
cd <project-directory>

# 2. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
ã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰ï¼ˆä¾‹: pip install -r requirements.txtï¼‰ã€‘

# 3. ç’°å¢ƒå¤‰æ•°ã®è¨­å®šï¼ˆå¿…è¦ãªå ´åˆï¼‰
ã€ç’°å¢ƒå¤‰æ•°ã®è¨­å®šæ–¹æ³•ã€‘
\```

## ğŸš€ ä½¿ã„æ–¹

### åŸºæœ¬çš„ãªå®Ÿè¡Œæ–¹æ³•

\```bash
# ã€å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã¨ç°¡å˜ãªèª¬æ˜ã€‘
ã€å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ï¼ˆä¾‹: python app.pyï¼‰ã€‘
\```

### ä½¿ç”¨ä¾‹

\```bash
# ä¾‹1: ã€ä½¿ç”¨ä¾‹1ã®èª¬æ˜ã€‘
ã€ã‚³ãƒãƒ³ãƒ‰ä¾‹1ã€‘

# ä¾‹2: ã€ä½¿ç”¨ä¾‹2ã®èª¬æ˜ã€‘
ã€ã‚³ãƒãƒ³ãƒ‰ä¾‹2ã€‘
\```

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

\```
ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ„ãƒªãƒ¼ã€‘
ä¾‹:
.
â”œâ”€â”€ README.md
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css
â””â”€â”€ templates/
    â””â”€â”€ index.html
\```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã€å•é¡Œ1ã€‘
- **ç—‡çŠ¶**: ã€ç—‡çŠ¶ã®èª¬æ˜ã€‘
- **è§£æ±ºæ–¹æ³•**: ã€è§£æ±ºæ–¹æ³•ã€‘

### ã€å•é¡Œ2ã€‘
- **ç—‡çŠ¶**: ã€ç—‡çŠ¶ã®èª¬æ˜ã€‘
- **è§£æ±ºæ–¹æ³•**: ã€è§£æ±ºæ–¹æ³•ã€‘

## ğŸ“ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License
\```

### ãƒ•ã‚¡ã‚¤ãƒ«: ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹1ï¼ˆä¾‹: app.pyï¼‰ã€‘
```ã€è¨€èªåã€‘
ã€å®Ÿè£…ã‚³ãƒ¼ãƒ‰ - å¿…è¦æœ€ä½é™ã ãŒå‹•ä½œã™ã‚‹å®Œå…¨ãªã‚³ãƒ¼ãƒ‰ã€‘
ã€è©³ç´°ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’å«ã‚ã‚‹ã€‘
ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã€‘
```

### ãƒ•ã‚¡ã‚¤ãƒ«: ã€ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹2ã€‘
```ã€è¨€èªåã€‘
ã€å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã€‘
```

### ãƒ•ã‚¡ã‚¤ãƒ«: requirements.txt
```
ã€ä¾å­˜é–¢ä¿‚ãƒªã‚¹ãƒˆã€‘
```

---

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †
1. ã€å…·ä½“çš„ãªæ‰‹é †1ã€‘
2. ã€å…·ä½“çš„ãªæ‰‹é †2ã€‘
3. ã€å…·ä½“çš„ãªæ‰‹é †3ã€‘

## å®Ÿè¡Œæ–¹æ³•
\```bash
# ã€å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã®èª¬æ˜ã€‘
ã€å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ã€‘
\```

---

**é‡è¦ãªè¦ä»¶:**
1. âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã¯è¦æ±‚å†…å®¹ã‚’åæ˜ ã—ãŸå…·ä½“çš„ãªåå‰ã«ã™ã‚‹
2. âœ… README.mdã‚’**å¿…ãšæœ€åˆã«**ç”Ÿæˆã™ã‚‹
3. âœ… README.mdã¯GitHubæ¨™æº–ã«æº–æ‹ ã—ãŸè¦‹ã‚„ã™ã„å½¢å¼ã§
4. âœ… Mermaidå›³ã¯å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’æ­£ç¢ºã«åæ˜ 
5. âœ… ã‚³ãƒ¼ãƒ‰ã¯å¿…è¦æœ€ä½é™ã ãŒå®Œå…¨ã«å‹•ä½œã™ã‚‹çŠ¶æ…‹
6. âœ… ã™ãã«å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ä¾å­˜é–¢ä¿‚ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã‚’æ˜è¨˜
7. âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã€ãƒ­ã‚°ã€è©³ç´°ãªã‚³ãƒ¡ãƒ³ãƒˆã‚’å«ã‚ã‚‹

**å‡ºåŠ›ä¾‹ï¼ˆæ§‹é€ è¨ˆç®—ã®å ´åˆã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåï¼‰:**
- âŒ æ‚ªã„ä¾‹: "generated-project", "sample-app"
- âœ… è‰¯ã„ä¾‹: "å»ºç¯‰æ§‹é€ è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ", "æ§‹é€ å®‰å…¨æ€§æ¤œè¨¼ãƒ„ãƒ¼ãƒ«"
"""
        
        return prompt

    def _extract_code_files(self, text: str) -> List[Dict[str, str]]:
        """
        ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚³ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŠ½å‡º
        
        å½¢å¼: ### ãƒ•ã‚¡ã‚¤ãƒ«: path/to/file.ext
              ```language
              code here
              ```
        """
        import re
        
        files = []
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³: ### ãƒ•ã‚¡ã‚¤ãƒ«: path/to/file.ext ã®å¾Œã« ``` ã§å›²ã¾ã‚ŒãŸã‚³ãƒ¼ãƒ‰
        pattern = r'###\s*ãƒ•ã‚¡ã‚¤ãƒ«:\s*([^\n]+)\s*```(\w+)?\s*\n(.*?)```'
        matches = re.finditer(pattern, text, re.DOTALL)
        
        for match in matches:
            filepath = match.group(1).strip()
            language = match.group(2) or self._detect_language_from_path(filepath)
            content = match.group(3).strip()
            
            files.append({
                "path": filepath,
                "content": content,
                "language": language,
            })
            
            print(f"  ğŸ“„ æŠ½å‡º: {filepath} ({language})")
        
        # ä»£æ›¿ãƒ‘ã‚¿ãƒ¼ãƒ³: ```language:filename
        alt_pattern = r'```(\w+):([^\n]+)\s*\n(.*?)```'
        alt_matches = re.finditer(alt_pattern, text, re.DOTALL)
        
        for match in alt_matches:
            language = match.group(1).strip()
            filepath = match.group(2).strip()
            content = match.group(3).strip()
            
            # æ—¢ã«åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒæŠ½å‡ºã•ã‚Œã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            if not any(f["path"] == filepath for f in files):
                files.append({
                    "path": filepath,
                    "content": content,
                    "language": language,
                })
                print(f"  ğŸ“„ æŠ½å‡ºï¼ˆä»£æ›¿å½¢å¼ï¼‰: {filepath} ({language})")
        
        return files

    def _extract_dependencies(self, text: str) -> List[str]:
        """ä¾å­˜é–¢ä¿‚ã‚’æŠ½å‡º"""
        import re
        
        dependencies = []
        
        # ## ä¾å­˜é–¢ä¿‚ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        dep_pattern = r'##\s*ä¾å­˜é–¢ä¿‚\s*```[^\n]*\n(.*?)```'
        match = re.search(dep_pattern, text, re.DOTALL)
        
        if match:
            dep_text = match.group(1).strip()
            # å„è¡Œã‚’ä¾å­˜é–¢ä¿‚ã¨ã—ã¦è¿½åŠ 
            for line in dep_text.split('\n'):
                line = line.strip()
                if line and not line.startswith('#'):
                    dependencies.append(line)
        
        return dependencies

    def _extract_instructions(self, text: str) -> str:
        """ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã¨å®Ÿè¡Œæ–¹æ³•ã‚’æŠ½å‡º"""
        import re
        
        instructions = []
        
        # ## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é † ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        setup_pattern = r'##\s*ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †\s*\n(.*?)(?=##|$)'
        setup_match = re.search(setup_pattern, text, re.DOTALL)
        
        if setup_match:
            instructions.append("# ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †")
            instructions.append(setup_match.group(1).strip())
        
        # ## å®Ÿè¡Œæ–¹æ³• ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¢ã™
        run_pattern = r'##\s*å®Ÿè¡Œæ–¹æ³•\s*\n(.*?)(?=##|$)'
        run_match = re.search(run_pattern, text, re.DOTALL)
        
        if run_match:
            instructions.append("\n# å®Ÿè¡Œæ–¹æ³•")
            instructions.append(run_match.group(1).strip())
        
        return "\n".join(instructions) if instructions else "ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã¯ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã«å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚"

    def _detect_language_from_path(self, filepath: str) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰è¨€èªã‚’æ¨æ¸¬"""
        ext_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.jsx': 'javascript',
            '.tsx': 'typescript',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.go': 'go',
            '.rs': 'rust',
            '.rb': 'ruby',
            '.php': 'php',
            '.swift': 'swift',
            '.kt': 'kotlin',
            '.scala': 'scala',
            '.sh': 'bash',
            '.html': 'html',
            '.css': 'css',
            '.json': 'json',
            '.yaml': 'yaml',
            '.yml': 'yaml',
            '.xml': 'xml',
            '.md': 'markdown',
        }
        
        import os
        _, ext = os.path.splitext(filepath)
        return ext_map.get(ext.lower(), 'text')
    
    def _extract_project_summary(self, text: str) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã‚’æŠ½å‡º"""
        import re
        
        summary = {
            "name": "ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "description": "",
            "features": [],
            "tech_stack": {
                "language": "",
                "framework": "",
                "libraries": []
            },
            "mermaid_diagram": ""
        }
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå
        name_pattern = r'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå:\s*(?:ã€)?([^ã€‘\n]+)(?:ã€‘)?'
        name_match = re.search(name_pattern, text)
        if name_match:
            summary["name"] = name_match.group(1).strip()
        
        # èª¬æ˜
        desc_pattern = r'èª¬æ˜:\s*(?:ã€)?([^ã€‘\n]+)(?:ã€‘)?'
        desc_match = re.search(desc_pattern, text)
        if desc_match:
            summary["description"] = desc_match.group(1).strip()
        
        # ä¸»ãªæ©Ÿèƒ½
        features_pattern = r'ä¸»ãªæ©Ÿèƒ½:?\s*\n((?:-\s+[^\n]+\n?)+)'
        features_match = re.search(features_pattern, text)
        if features_match:
            for line in features_match.group(1).split('\n'):
                if line.strip().startswith('-'):
                    feature = line.strip()[1:].strip()
                    if feature:
                        summary["features"].append(feature)
        
        # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
        lang_pattern = r'-\s*è¨€èª:\s*(?:ã€)?([^ã€‘\n]+)(?:ã€‘)?'
        lang_match = re.search(lang_pattern, text)
        if lang_match:
            summary["tech_stack"]["language"] = lang_match.group(1).strip()
        
        fw_pattern = r'-\s*ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯:\s*(?:ã€)?([^ã€‘\n]+)(?:ã€‘)?'
        fw_match = re.search(fw_pattern, text)
        if fw_match:
            summary["tech_stack"]["framework"] = fw_match.group(1).strip()
        
        lib_pattern = r'-\s*ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª:\s*(?:ã€)?([^ã€‘\n]+)(?:ã€‘)?'
        lib_match = re.search(lib_pattern, text)
        if lib_match:
            libs = lib_match.group(1).strip()
            summary["tech_stack"]["libraries"] = [l.strip() for l in libs.split(',') if l.strip()]
        
        # Mermaidå›³
        mermaid_pattern = r'```mermaid\s*\n(.*?)```'
        mermaid_match = re.search(mermaid_pattern, text, re.DOTALL)
        if mermaid_match:
            summary["mermaid_diagram"] = mermaid_match.group(1).strip()
        
        return summary

    def _analyze_image_with_provider(
        self,
        image_base64: str,
        prompt: str,
        provider: str,
    ) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ç”»åƒåˆ†æã‚’å®Ÿè¡Œ

        Args:
            image_base64: Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            provider: 'openai' ã¾ãŸã¯ 'anthropic'

        Returns:
            ç”»åƒåˆ†æçµæœ
        """
        if provider == "openai":
            from openai import OpenAI
            
            print(f"  ğŸ¤– OpenAI ({self.openai_model})ã§ç”»åƒåˆ†æä¸­...")
            client = OpenAI(api_key=self.openai_api_key)
            
            response = client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=1024,
            )
            
            return {
                "analysis": response.choices[0].message.content,
                "model": self.openai_model,
                "timestamp": datetime.now().isoformat(),
            }
            
        elif provider == "anthropic":
            from anthropic import Anthropic
            
            print(f"  ğŸ¤– Anthropic ({self.anthropic_model})ã§ç”»åƒåˆ†æä¸­...")
            client = Anthropic(api_key=self.anthropic_api_key)
            
            response = client.messages.create(
                model=self.anthropic_model,
                max_tokens=1024,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/jpeg",
                                    "data": image_base64,
                                },
                            },
                            {"type": "text", "text": prompt},
                        ],
                    }
                ],
            )
            
            return {
                "analysis": response.content[0].text,
                "model": self.anthropic_model,
                "timestamp": datetime.now().isoformat(),
            }
        else:
            raise ValueError(f"æœªã‚µãƒãƒ¼ãƒˆã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider}")

    def _generate_text_with_provider(
        self,
        prompt: str,
        provider: str,
        max_tokens: int = 4096,
    ) -> Dict[str, Any]:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œ

        Args:
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            provider: 'openai' ã¾ãŸã¯ 'anthropic'
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°

        Returns:
            ç”Ÿæˆçµæœ
        """
        if provider == "openai":
            from openai import OpenAI
            
            print(f"  ğŸ¤– OpenAI ({self.openai_model})ã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆä¸­...")
            client = OpenAI(api_key=self.openai_api_key)
            
            response = client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=max_tokens,
            )
            
            return {
                "content": response.choices[0].message.content,
                "model": self.openai_model,
            }
            
        elif provider == "anthropic":
            from anthropic import Anthropic
            
            print(f"  ğŸ¤– Anthropic ({self.anthropic_model})ã§ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆä¸­...")
            client = Anthropic(api_key=self.anthropic_api_key)
            
            response = client.messages.create(
                model=self.anthropic_model,
                max_tokens=max_tokens,
                messages=[
                    {
                        "role": "user",
                        "content": prompt,
                    }
                ],
            )
            
            return {
                "content": response.content[0].text,
                "model": self.anthropic_model,
            }
        else:
            raise ValueError(f"æœªã‚µãƒãƒ¼ãƒˆã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider}")


# FastAPI Webã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.function(image=image, secrets=secrets)
@modal.asgi_app()
def fastapi_app():
    """
    FastAPI Webã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
    """
    from fastapi import FastAPI, UploadFile, File, Form, Request
    from fastapi.responses import JSONResponse

    web_app = FastAPI(title="Realworld Agent GPU API")

    @web_app.get("/")
    async def root():
        return {
            "name": "Realworld Agent GPU Server",
            "version": "0.1.0",
            "status": "running",
        }

    @web_app.get("/health")
    async def health():
        return {"status": "healthy"}

    @web_app.post("/api/transcribe")
    async def transcribe(
        audio: UploadFile = File(...),
        language: str = Form("ja"),
        enable_diarization: bool = Form(True),
    ):
        """éŸ³å£°æ–‡å­—èµ·ã“ã—API"""
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            temp_path = f"/tmp/{audio.filename}"
            with open(temp_path, "wb") as f:
                f.write(await audio.read())

            # GPUã‚¯ãƒ©ã‚¹ã‚’å‘¼ã³å‡ºã—
            gpu = RealworldAgentGPU()
            result = gpu.transcribe_audio.remote(
                temp_path,
                language=language,
                enable_diarization=enable_diarization,
            )

            return JSONResponse(content=result)

        except Exception as e:
            return JSONResponse(
                status_code=500,
                content={"error": str(e)},
            )

    @web_app.post("/api/analyze-image")
    async def analyze_image(image: UploadFile = File(...)):
        """ç”»åƒåˆ†æAPI"""
        try:
            image_data = await image.read()

            gpu = RealworldAgentGPU()
            result = gpu.analyze_image.remote(image_data)

            return JSONResponse(content=result)

        except Exception as e:
            return JSONResponse(
                status_code=500,
                content={"error": str(e)},
            )

    @web_app.post("/generate-spec")
    async def generate_specification(request: Request):
        """ä»•æ§˜æ›¸ç”ŸæˆAPI"""
        try:
            body = await request.json()
            context = body.get("context", {})

            gpu = RealworldAgentGPU()
            result = gpu.generate_specification.remote(context)

            return JSONResponse(content=result)

        except Exception as e:
            return JSONResponse(
                status_code=500,
                content={"error": str(e)},
            )

    @web_app.post("/api/generate-code")
    async def generate_code(request: Request):
        """ã‚³ãƒ¼ãƒ‰ç”ŸæˆAPI"""
        try:
            body = await request.json()

            gpu = RealworldAgentGPU()
            result = gpu.generate_code.remote(body)

            return JSONResponse(content=result)

        except Exception as e:
            return JSONResponse(
                status_code=500,
                content={"error": str(e)},
            )

    return web_app

